# Building Transformer Models with Attention
## Implementation from Scratch in Tensorflow Keras

Following [this book](https://machinelearningmastery.com/transformer-models-with-attention/) to teach myself about the transformer architecture in depth.

Some *excellent* resources I've come across along the way:
* [Illustrated Guide to Transformers Neural Network: A step by step explanation](https://youtu.be/4Bdc55j80l8) - by Michael Phi ([@LearnedVector](https://github.com/LearnedVector))
* [Let's build GPT: from scratch, in code, spelled out.](https://youtu.be/kCc8FmEb1nY) - by the legendary Andrej Karpathy ([@karpathy](https://github.com/karpathy))
* [Transformers from Scratch](https://peterbloem.nl/blog/transformers) - by Peter Bloem ([@pbloem](https://github.com/pbloem))
* [Lil'Log > The Transformer Family Version 2.0](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/) - by Lilian Weng ([@lilianweng](https://github.com/lilianweng))
* [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) - by Jay Alammar ([@jalammar](https://jalammar.github.io/))
* [Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/) - by Amirhossein Kazemnejad ([@kazemnejad](https://github.com/kazemnejad))
* [Dive into Deep Learning > Attention Mechanisms and Transformers](https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html)
* [Harvard NLP > The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
* Towards Data Science > Transformers Explained Visually: [Part 1](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452), [Part 2](https://towardsdatascience.com/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34), [Part 3](https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853) and [Part 4](https://towardsdatascience.com/transformers-explained-visually-not-just-how-but-why-they-work-so-well-d840bd61a9d3) - by [Ketan Doshi](https://ketanhdoshi.medium.com/)
* [Lecture 12](https://www.youtube.com/playlist?list=PLIXJ-Sacf8u60G1TwcznBmK6rEL3gmZmV) of the "Deep Learning at the Vrije Universiteit Amsterdam" (DLVU) Series - by Peter Bloem ([@pbloem](https://github.com/pbloem))
* [Natural Language Processing in Action Using Transformers in TensorFlow 2.0](https://youtu.be/07iAf5_eix0?si=gBvYSfrKgHlwqsSo) - by Aur√©lien Geron [(@ageron)](https://github.com/ageron)

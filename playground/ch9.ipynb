{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6048ac9-25ac-4268-a58b-b5ff6dc322ea",
   "metadata": {},
   "source": [
    "# 9 Adding a Custom Attention Layer to Recurrent Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f4955b-6441-4a27-81bf-6e421c7463c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:52.435479Z",
     "iopub.status.busy": "2023-06-26T00:09:52.435294Z",
     "iopub.status.idle": "2023-06-26T00:09:54.700741Z",
     "shell.execute_reply": "2023-06-26T00:09:54.700456Z",
     "shell.execute_reply.started": "2023-06-26T00:09:52.435434Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, SimpleRNN\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796d0a9-ef75-4959-a165-c80838d50d88",
   "metadata": {},
   "source": [
    "## 9.2 The SimpleRNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1e476-b0d3-4afe-b747-34df0e3a74e1",
   "metadata": {},
   "source": [
    "Our aim is to train an RNN on the Fibonacci numbers and get it to predict the next term given the first few.  \n",
    "First, we need to construct the data for our contrived prediction problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feec2bf3-1da8-437a-a1eb-72c77b5a1b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.701988Z",
     "iopub.status.busy": "2023-06-26T00:09:54.701795Z",
     "iopub.status.idle": "2023-06-26T00:09:54.704526Z",
     "shell.execute_reply": "2023-06-26T00:09:54.704262Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.701978Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fib_seq(n, scale_data=True):\n",
    "    \"\"\"\n",
    "    Get the first n terms of the Fibonacci sequence,\n",
    "    excluding the initial (0, 1).\n",
    "    \"\"\"\n",
    "    seq = np.zeros(n)\n",
    "    fib_2_prior = 0.0\n",
    "    fib_1_prior = 1.0\n",
    "    for i in range(n):\n",
    "        seq[i] = fib_2_prior + fib_1_prior\n",
    "        fib_2_prior = fib_1_prior\n",
    "        fib_1_prior = seq[i]\n",
    "    scaler = None\n",
    "    if scale_data:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        seq = np.reshape(seq, (n, 1))\n",
    "        seq = scaler.fit_transform(seq).flatten()\n",
    "    return seq, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f529a7cf-462c-4cda-9974-3b9f86a395fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.705143Z",
     "iopub.status.busy": "2023-06-26T00:09:54.705010Z",
     "iopub.status.idle": "2023-06-26T00:09:54.707170Z",
     "shell.execute_reply": "2023-06-26T00:09:54.706887Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.705134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  5.  8. 13. 21. 34. 55. 89.]\n"
     ]
    }
   ],
   "source": [
    "fib_seq, _ = get_fib_seq(10, False)\n",
    "print(fib_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c730068-23d2-46d4-b28e-a03f685d398d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.707608Z",
     "iopub.status.busy": "2023-06-26T00:09:54.707530Z",
     "iopub.status.idle": "2023-06-26T00:09:54.711237Z",
     "shell.execute_reply": "2023-06-26T00:09:54.710952Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.707600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fib_xy(total_fib_numbers, time_steps, train_frac, scale_data=True):\n",
    "    \"\"\"Returns train/test data constructed from the Fibonacci series.\n",
    "\n",
    "    Constructs training and test data (as X and y pairs),  where each row of X\n",
    "    consists of `time_steps` consecutive Fibonacci numbers and each y is the\n",
    "    Fibonacci number immediately following the last one in the corresponding X.\n",
    "\n",
    "    Args:\n",
    "        total_fib_numbers: Total number of terms of the Fibonacci series to use\n",
    "          to draw from to construct X/y pairs. (Excludes the initial 0, 1)\n",
    "        time_steps: Number of terms in each X sample.\n",
    "        train_frac: Fraction of data to designate as the training set.\n",
    "        scale_data: Whether to min-max-scale the data to the (0, 1) range.\n",
    "\n",
    "    Returns:\n",
    "        Shuffled training and testing pairs of (X, y) data and, optionally, a\n",
    "        MinMaxScaler object (or None). The returned X tensors are of dimensions\n",
    "        (num_samples, num_time_steps, num_features = 1).\n",
    "    \"\"\"\n",
    "    data, scaler = get_fib_seq(total_fib_numbers, scale_data)\n",
    "\n",
    "    y_indices = np.arange(time_steps, len(data), 1)\n",
    "    y = data[y_indices]\n",
    "    num_samples = len(y)\n",
    "    X = data[0:num_samples]\n",
    "    for i in range(1, time_steps):\n",
    "        X = np.column_stack((X, data[i : num_samples + i]))\n",
    "\n",
    "    # Now introduce random permutations\n",
    "    rand = np.random.RandomState(seed)\n",
    "    indices = rand.permutation(num_samples)\n",
    "    split = int(train_frac * num_samples)\n",
    "    train_indices = indices[0:split]\n",
    "    test_indices = indices[split:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    X_train = np.reshape(X_train, (len(X_train), time_steps, 1))\n",
    "    X_test = np.reshape(X_test, (len(X_test), time_steps, 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e16388e-58eb-40b8-ae29-ba121fff9a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.711797Z",
     "iopub.status.busy": "2023-06-26T00:09:54.711707Z",
     "iopub.status.idle": "2023-06-26T00:09:54.717371Z",
     "shell.execute_reply": "2023-06-26T00:09:54.717092Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.711788Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 8.],\n",
       "         [13.],\n",
       "         [21.]],\n",
       " \n",
       "        [[ 5.],\n",
       "         [ 8.],\n",
       "         [13.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 3.],\n",
       "         [ 5.]],\n",
       " \n",
       "        [[13.],\n",
       "         [21.],\n",
       "         [34.]],\n",
       " \n",
       "        [[21.],\n",
       "         [34.],\n",
       "         [55.]],\n",
       " \n",
       "        [[34.],\n",
       "         [55.],\n",
       "         [89.]]]),\n",
       " array([ 34.,  21.,   8.,  55.,  89., 144.]),\n",
       " array([[[ 55.],\n",
       "         [ 89.],\n",
       "         [144.]],\n",
       " \n",
       "        [[  1.],\n",
       "         [  2.],\n",
       "         [  3.]],\n",
       " \n",
       "        [[  3.],\n",
       "         [  5.],\n",
       "         [  8.]]]),\n",
       " array([233.,   5.,  13.]),\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fib_xy(12, 3, 0.7, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49338e-6f69-4108-b9f2-8768e475fa58",
   "metadata": {},
   "source": [
    "Great! Now let us build a model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb36d08-ca58-4fad-b333-17350c8bf546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.717965Z",
     "iopub.status.busy": "2023-06-26T00:09:54.717860Z",
     "iopub.status.idle": "2023-06-26T00:09:54.720585Z",
     "shell.execute_reply": "2023-06-26T00:09:54.720175Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.717956Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "time_steps = 20\n",
    "hidden_units = 2\n",
    "epochs = 30\n",
    "\n",
    "# Create a traditional RNN network\n",
    "def create_rnn(hidden_units, dense_units, input_shape, activations):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        SimpleRNN(\n",
    "            hidden_units, input_shape=input_shape, activation=activations[0]\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(dense_units, activation=activations[1]))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45b17a9-8e29-49ce-90ea-0fd13455ad5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.723114Z",
     "iopub.status.busy": "2023-06-26T00:09:54.722887Z",
     "iopub.status.idle": "2023-06-26T00:09:54.791308Z",
     "shell.execute_reply": "2023-06-26T00:09:54.790868Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.723103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 2)                 8         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn = create_rnn(\n",
    "    hidden_units=hidden_units,\n",
    "    dense_units=1,\n",
    "    input_shape=(time_steps, 1),\n",
    "    activations=[\"tanh\", \"tanh\"],\n",
    ")\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edbf0d-0442-408c-bcdf-e507226ea2f2",
   "metadata": {},
   "source": [
    "Question\n",
    "> Why does the Simple RNN layer have 8 parameters?  \n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    (2 hidden units + 1 input feature) × (2 hidden units) + 2 biases\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "Now we are ready to create a larger dataset and train the model on it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8d8f7e-cbe1-4fd0-917d-029b515f857d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.792006Z",
     "iopub.status.busy": "2023-06-26T00:09:54.791891Z",
     "iopub.status.idle": "2023-06-26T00:09:54.796448Z",
     "shell.execute_reply": "2023-06-26T00:09:54.796161Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.791996Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "X_train, y_train, X_test, y_test, scaler = get_fib_xy(1200, time_steps, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73ae6ed-5e2b-491e-9aeb-5e94bdec7c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:09:54.797243Z",
     "iopub.status.busy": "2023-06-26T00:09:54.797114Z",
     "iopub.status.idle": "2023-06-26T00:10:13.705104Z",
     "shell.execute_reply": "2023-06-26T00:10:13.704809Z",
     "shell.execute_reply.started": "2023-06-26T00:09:54.797233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 17:09:54.888097: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 - 1s - loss: 0.0011 - 948ms/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 1s - loss: 9.9148e-04 - 613ms/epoch - 742us/step\n",
      "Epoch 3/30\n",
      "826/826 - 1s - loss: 9.0618e-04 - 614ms/epoch - 743us/step\n",
      "Epoch 4/30\n",
      "826/826 - 1s - loss: 8.2918e-04 - 625ms/epoch - 757us/step\n",
      "Epoch 5/30\n",
      "826/826 - 1s - loss: 7.5973e-04 - 618ms/epoch - 748us/step\n",
      "Epoch 6/30\n",
      "826/826 - 1s - loss: 6.8731e-04 - 623ms/epoch - 754us/step\n",
      "Epoch 7/30\n",
      "826/826 - 1s - loss: 5.9476e-04 - 617ms/epoch - 747us/step\n",
      "Epoch 8/30\n",
      "826/826 - 1s - loss: 5.1964e-04 - 610ms/epoch - 739us/step\n",
      "Epoch 9/30\n",
      "826/826 - 1s - loss: 4.3435e-04 - 613ms/epoch - 743us/step\n",
      "Epoch 10/30\n",
      "826/826 - 1s - loss: 3.4466e-04 - 613ms/epoch - 742us/step\n",
      "Epoch 11/30\n",
      "826/826 - 1s - loss: 2.8283e-04 - 616ms/epoch - 745us/step\n",
      "Epoch 12/30\n",
      "826/826 - 1s - loss: 2.1911e-04 - 618ms/epoch - 748us/step\n",
      "Epoch 13/30\n",
      "826/826 - 1s - loss: 1.6960e-04 - 615ms/epoch - 745us/step\n",
      "Epoch 14/30\n",
      "826/826 - 1s - loss: 1.3832e-04 - 618ms/epoch - 748us/step\n",
      "Epoch 15/30\n",
      "826/826 - 1s - loss: 1.1235e-04 - 616ms/epoch - 746us/step\n",
      "Epoch 16/30\n",
      "826/826 - 1s - loss: 9.9631e-05 - 612ms/epoch - 741us/step\n",
      "Epoch 17/30\n",
      "826/826 - 1s - loss: 9.8266e-05 - 612ms/epoch - 741us/step\n",
      "Epoch 18/30\n",
      "826/826 - 1s - loss: 9.0481e-05 - 613ms/epoch - 742us/step\n",
      "Epoch 19/30\n",
      "826/826 - 1s - loss: 9.0453e-05 - 615ms/epoch - 744us/step\n",
      "Epoch 20/30\n",
      "826/826 - 1s - loss: 8.4129e-05 - 611ms/epoch - 739us/step\n",
      "Epoch 21/30\n",
      "826/826 - 1s - loss: 7.9450e-05 - 615ms/epoch - 745us/step\n",
      "Epoch 22/30\n",
      "826/826 - 1s - loss: 8.1487e-05 - 615ms/epoch - 744us/step\n",
      "Epoch 23/30\n",
      "826/826 - 1s - loss: 8.0797e-05 - 618ms/epoch - 748us/step\n",
      "Epoch 24/30\n",
      "826/826 - 1s - loss: 7.6091e-05 - 615ms/epoch - 745us/step\n",
      "Epoch 25/30\n",
      "826/826 - 1s - loss: 8.0704e-05 - 616ms/epoch - 745us/step\n",
      "Epoch 26/30\n",
      "826/826 - 1s - loss: 7.3596e-05 - 614ms/epoch - 743us/step\n",
      "Epoch 27/30\n",
      "826/826 - 1s - loss: 7.6416e-05 - 616ms/epoch - 746us/step\n",
      "Epoch 28/30\n",
      "826/826 - 1s - loss: 7.2598e-05 - 618ms/epoch - 748us/step\n",
      "Epoch 29/30\n",
      "826/826 - 1s - loss: 6.8195e-05 - 612ms/epoch - 740us/step\n",
      "Epoch 30/30\n",
      "826/826 - 1s - loss: 7.4732e-05 - 613ms/epoch - 742us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28eb28d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578b886b-43e6-4464-927e-1d0a2f1a2d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:13.705754Z",
     "iopub.status.busy": "2023-06-26T00:10:13.705645Z",
     "iopub.status.idle": "2023-06-26T00:10:13.876775Z",
     "shell.execute_reply": "2023-06-26T00:10:13.876437Z",
     "shell.execute_reply.started": "2023-06-26T00:10:13.705745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 710us/step - loss: 5.9327e-05\n",
      "12/12 [==============================] - 0s 662us/step - loss: 2.0649e-05\n",
      "Train set MSE =  5.9327030612621456e-05\n",
      "Test set MSE =  2.0648820282076485e-05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_mse = model_rnn.evaluate(X_train, y_train)\n",
    "test_mse = model_rnn.evaluate(X_test, y_test)\n",
    "print(\"Train set MSE = \", train_mse)\n",
    "print(\"Test set MSE = \", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5bf6e-2161-4b34-bfa4-1c2f4ef7c1b3",
   "metadata": {},
   "source": [
    "## 9.3 Adding a Custom Attention Layer to the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0f5bf-fa90-4ab5-9a37-1b2aba2ecf0d",
   "metadata": {},
   "source": [
    "We will create the `Attention` class which inherits from Keras's `Layer` class. Our class will implement the Bahdanau attention mechanism.  \n",
    "In order to build a custom layer, Keras requires us to implement the `__init__()`, `build()` and `call()` methods. The `build` method \"lazily\" builds the weights and biases once the input shape is known. The `call()` method implements the forward pass of training. Everything else (computing gradients and tuning the weights via the backward pass) is taken care of by Keras.  \n",
    "\n",
    "See the Keras guide on [Making new layers and models via subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a657a0a0-c4a7-4941-a34c-ccde81281c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:13.877368Z",
     "iopub.status.busy": "2023-06-26T00:10:13.877272Z",
     "iopub.status.idle": "2023-06-26T00:10:13.881641Z",
     "shell.execute_reply": "2023-06-26T00:10:13.880653Z",
     "shell.execute_reply.started": "2023-06-26T00:10:13.877358Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name=\"attention_weight\",\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name=\"attention_bias\",\n",
    "            shape=(input_shape[1], 1),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Compute alignment scores and pass them thru the `tanh` function\n",
    "        e = K.tanh(K.dot(x, self.w) + self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        # Compute the attention weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to the format TensorFlow needs (adding back the removed dim)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62fb8b-0254-475c-afed-bd9c48d9f87c",
   "metadata": {},
   "source": [
    "We can now create an RNN with attention using the \"Functional API\" of Keras. Our attention layer expects a sequence as input, so we will have to make sure to return the entire sequence of hidden states from our SimpleRNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b240abdb-7f6b-418d-a948-60f9c566ad30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:13.882605Z",
     "iopub.status.busy": "2023-06-26T00:10:13.882404Z",
     "iopub.status.idle": "2023-06-26T00:10:13.886456Z",
     "shell.execute_reply": "2023-06-26T00:10:13.885969Z",
     "shell.execute_reply.started": "2023-06-26T00:10:13.882586Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_with_attention(\n",
    "    hidden_units, dense_units, input_shape, activation\n",
    "):\n",
    "    x = Input(shape=input_shape)\n",
    "    rnn_layer = SimpleRNN(\n",
    "        hidden_units, return_sequences=True, activation=activation\n",
    "    )(x)\n",
    "    attention_layer = Attention()(rnn_layer)\n",
    "    outputs = Dense(dense_units, trainable=True, activation=activation)(\n",
    "        attention_layer\n",
    "    )\n",
    "    model = Model(x, outputs)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50241826-4e2b-4552-a450-2bfc71b45f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:13.887375Z",
     "iopub.status.busy": "2023-06-26T00:10:13.887141Z",
     "iopub.status.idle": "2023-06-26T00:10:13.967063Z",
     "shell.execute_reply": "2023-06-26T00:10:13.966744Z",
     "shell.execute_reply.started": "2023-06-26T00:10:13.887359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 20, 2)             8         \n",
      "                                                                 \n",
      " attention (Attention)       (None, 2)                 22        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_attention = create_rnn_with_attention(\n",
    "    hidden_units=hidden_units,\n",
    "    dense_units=1,\n",
    "    input_shape=(time_steps, 1),\n",
    "    activation=\"tanh\",\n",
    ")\n",
    "model_attention.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fcc3d-fc9a-4bb2-8c70-78236fe1e347",
   "metadata": {},
   "source": [
    "We can now train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb7b07c-3876-409f-8949-ed346837c985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:13.967557Z",
     "iopub.status.busy": "2023-06-26T00:10:13.967466Z",
     "iopub.status.idle": "2023-06-26T00:10:34.961767Z",
     "shell.execute_reply": "2023-06-26T00:10:34.961476Z",
     "shell.execute_reply.started": "2023-06-26T00:10:13.967548Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 1s - loss: 0.0015 - 1s/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 1s - loss: 0.0015 - 680ms/epoch - 823us/step\n",
      "Epoch 3/30\n",
      "826/826 - 1s - loss: 0.0015 - 681ms/epoch - 825us/step\n",
      "Epoch 4/30\n",
      "826/826 - 1s - loss: 0.0014 - 685ms/epoch - 829us/step\n",
      "Epoch 5/30\n",
      "826/826 - 1s - loss: 0.0014 - 685ms/epoch - 829us/step\n",
      "Epoch 6/30\n",
      "826/826 - 1s - loss: 0.0015 - 682ms/epoch - 826us/step\n",
      "Epoch 7/30\n",
      "826/826 - 1s - loss: 0.0014 - 686ms/epoch - 830us/step\n",
      "Epoch 8/30\n",
      "826/826 - 1s - loss: 0.0014 - 697ms/epoch - 844us/step\n",
      "Epoch 9/30\n",
      "826/826 - 1s - loss: 0.0014 - 684ms/epoch - 828us/step\n",
      "Epoch 10/30\n",
      "826/826 - 1s - loss: 0.0014 - 681ms/epoch - 824us/step\n",
      "Epoch 11/30\n",
      "826/826 - 1s - loss: 0.0014 - 681ms/epoch - 824us/step\n",
      "Epoch 12/30\n",
      "826/826 - 1s - loss: 0.0014 - 687ms/epoch - 832us/step\n",
      "Epoch 13/30\n",
      "826/826 - 1s - loss: 0.0013 - 676ms/epoch - 818us/step\n",
      "Epoch 14/30\n",
      "826/826 - 1s - loss: 0.0013 - 679ms/epoch - 822us/step\n",
      "Epoch 15/30\n",
      "826/826 - 1s - loss: 0.0013 - 702ms/epoch - 850us/step\n",
      "Epoch 16/30\n",
      "826/826 - 1s - loss: 0.0012 - 720ms/epoch - 872us/step\n",
      "Epoch 17/30\n",
      "826/826 - 1s - loss: 0.0012 - 690ms/epoch - 835us/step\n",
      "Epoch 18/30\n",
      "826/826 - 1s - loss: 0.0011 - 699ms/epoch - 847us/step\n",
      "Epoch 19/30\n",
      "826/826 - 1s - loss: 0.0011 - 683ms/epoch - 827us/step\n",
      "Epoch 20/30\n",
      "826/826 - 1s - loss: 0.0010 - 688ms/epoch - 833us/step\n",
      "Epoch 21/30\n",
      "826/826 - 1s - loss: 9.7350e-04 - 680ms/epoch - 823us/step\n",
      "Epoch 22/30\n",
      "826/826 - 1s - loss: 9.0705e-04 - 678ms/epoch - 821us/step\n",
      "Epoch 23/30\n",
      "826/826 - 1s - loss: 8.3914e-04 - 689ms/epoch - 834us/step\n",
      "Epoch 24/30\n",
      "826/826 - 1s - loss: 7.6669e-04 - 681ms/epoch - 825us/step\n",
      "Epoch 25/30\n",
      "826/826 - 1s - loss: 6.7912e-04 - 683ms/epoch - 827us/step\n",
      "Epoch 26/30\n",
      "826/826 - 1s - loss: 6.0955e-04 - 681ms/epoch - 824us/step\n",
      "Epoch 27/30\n",
      "826/826 - 1s - loss: 5.3535e-04 - 687ms/epoch - 831us/step\n",
      "Epoch 28/30\n",
      "826/826 - 1s - loss: 4.5935e-04 - 683ms/epoch - 827us/step\n",
      "Epoch 29/30\n",
      "826/826 - 1s - loss: 4.0674e-04 - 680ms/epoch - 823us/step\n",
      "Epoch 30/30\n",
      "826/826 - 1s - loss: 3.3650e-04 - 680ms/epoch - 823us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f98ad70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attention.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28039634-8498-4112-9478-c246966bb71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:34.962450Z",
     "iopub.status.busy": "2023-06-26T00:10:34.962323Z",
     "iopub.status.idle": "2023-06-26T00:10:35.126390Z",
     "shell.execute_reply": "2023-06-26T00:10:35.126092Z",
     "shell.execute_reply.started": "2023-06-26T00:10:34.962440Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 730us/step - loss: 2.7651e-04\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0968e-04\n",
      "Train set MSE =  0.0002765108074527234\n",
      "Test set MSE =  0.0001096751366276294\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_mse_attn = model_attention.evaluate(X_train, y_train)\n",
    "test_mse_attn = model_attention.evaluate(X_test, y_test)\n",
    "print(\"Train set MSE = \", train_mse_attn)\n",
    "print(\"Test set MSE = \", test_mse_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7af29d-023f-4a1c-ac1a-75e9bce9bc8b",
   "metadata": {},
   "source": [
    "This is a very contrived, simple example and the model with attention may or may not beat the one without.  \n",
    "We could potentially improve the model further by trying the following:\n",
    "- Hyperparameter tuning and model selection\n",
    "- Adding more layers to the network\n",
    "- Using `LSTM` units instead of `SimpleRNN`s\n",
    "- Building a network with convolution and pooling layers\n",
    "- Switching to the encoder-decoder model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707616ea-cf96-42e2-a69b-6ad75504843e",
   "metadata": {},
   "source": [
    "**Note:** We can use the `scaler` object to convert back to the original values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1dc34f-9035-4e34-91e6-73945b9460c3",
   "metadata": {},
   "source": [
    "**Personal Note:** Actually this dataset is pretty useless and not suited to this kind of model. I found out as much while trying to convert the predictions back to the original range as per the above note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06779d31-b189-49f9-a861-bd851545750a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:35.126998Z",
     "iopub.status.busy": "2023-06-26T00:10:35.126900Z",
     "iopub.status.idle": "2023-06-26T00:10:35.313428Z",
     "shell.execute_reply": "2023-06-26T00:10:35.313131Z",
     "shell.execute_reply.started": "2023-06-26T00:10:35.126989Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example test case (unscaled):\n",
      "[1.43670136e+188 2.32463163e+188 3.76133300e+188 6.08596463e+188\n",
      " 9.84729763e+188 1.59332623e+189 2.57805599e+189 4.17138221e+189\n",
      " 6.74943820e+189 1.09208204e+190 1.76702586e+190 2.85910790e+190\n",
      " 4.62613377e+190 7.48524167e+190 1.21113754e+191 1.95966171e+191\n",
      " 3.17079925e+191 5.13046096e+191 8.30126022e+191 1.34317212e+192]\n",
      "\n",
      "\n",
      "The correct next term is: 8.301260217870547e+191 + 1.34317211819719e+192 = 2.1732981399842448e+192\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "The model predicted: 9.401819363672982e+246\n"
     ]
    }
   ],
   "source": [
    "fib_seq, _ = get_fib_seq(920, False)\n",
    "\n",
    "example = fib_seq[900:]\n",
    "print(f\"Example test case (unscaled):\\n{example}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "actual_next_term = example[-2] + example[-1]\n",
    "print(\n",
    "    f\"The correct next term is: {example[-2]} + {example[-1]} =\"\n",
    "    f\" {actual_next_term}\"\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "example_scaled = scaler.transform(np.reshape(example, (time_steps, 1)))\n",
    "predicted_term = model_attention.predict(np.expand_dims(example_scaled, 0))\n",
    "predicted_term_scaled = predicted_term[0][0]\n",
    "predicted_term_scaled\n",
    "print(f\"The model predicted: {scaler.inverse_transform([[predicted_term_scaled]])[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4146e-5f2a-4277-ae3c-4a7173d09e7a",
   "metadata": {},
   "source": [
    "My first reaction was: \"Why are they so far off?!\" Then I looked at a few arbitrary 20-term sub-sequences of the Fibonacci series and got the exact same result. And by \"exact same result\" I don't mean \"same huge error\". No! I mean the exact same prediction!! As a matter of fact, let's take a look at the model's predictions on the entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77b022df-d838-4333-91d0-82802f270748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T00:10:35.314096Z",
     "iopub.status.busy": "2023-06-26T00:10:35.313940Z",
     "iopub.status.idle": "2023-06-26T00:10:35.361382Z",
     "shell.execute_reply": "2023-06-26T00:10:35.361076Z",
     "shell.execute_reply.started": "2023-06-26T00:10:35.314087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 713us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1308661e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [4.1934839e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.0167980e-01],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [7.2718024e-02],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1308661e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.5073532e-03],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [4.2484561e-01],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.6173890e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [7.5329817e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1310151e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [5.4685015e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04],\n",
       "       [2.1304935e-04]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attention.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121298e6-13e0-4dcf-9a63-8f1768f466f8",
   "metadata": {},
   "source": [
    "Yup! They are mostly identical. Why? Because the $1200^{th}$ Fibonacci number has 250 digits (‼️) and when you map a range as wide as $(1, F_{1200})$ to the (0, 1) range in the scaling step, you can't expect a much better result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6f3d1-7bba-4ef0-9ff6-721353886287",
   "metadata": {},
   "source": [
    "If I get a chance later on, I will try to re-do this chapter with the sunspot dataset (from ch. 7) instead of this contrived Fibonacci-based one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6048ac9-25ac-4268-a58b-b5ff6dc322ea",
   "metadata": {},
   "source": [
    "# 9 Adding a Custom Attention Layer to Recurrent Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f4955b-6441-4a27-81bf-6e421c7463c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.521672Z",
     "iopub.status.busy": "2023-06-26T04:57:10.521033Z",
     "iopub.status.idle": "2023-06-26T04:57:10.534177Z",
     "shell.execute_reply": "2023-06-26T04:57:10.533068Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.521598Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Layer, SimpleRNN\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "seed = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796d0a9-ef75-4959-a165-c80838d50d88",
   "metadata": {},
   "source": [
    "## 9.2 The SimpleRNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1e476-b0d3-4afe-b747-34df0e3a74e1",
   "metadata": {},
   "source": [
    "Our aim is to train an RNN on the Fibonacci numbers and get it to predict the next term given the first few.  \n",
    "First, we need to construct the data for our contrived prediction problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feec2bf3-1da8-437a-a1eb-72c77b5a1b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.538064Z",
     "iopub.status.busy": "2023-06-26T04:57:10.537393Z",
     "iopub.status.idle": "2023-06-26T04:57:10.545400Z",
     "shell.execute_reply": "2023-06-26T04:57:10.544973Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.538032Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fib_seq(n, scale_data=True):\n",
    "    \"\"\"\n",
    "    Get the first n terms of the Fibonacci sequence,\n",
    "    excluding the initial (0, 1).\n",
    "    \"\"\"\n",
    "    seq = np.zeros(n)\n",
    "    fib_2_prior = 0.0\n",
    "    fib_1_prior = 1.0\n",
    "    for i in range(n):\n",
    "        seq[i] = fib_2_prior + fib_1_prior\n",
    "        fib_2_prior = fib_1_prior\n",
    "        fib_1_prior = seq[i]\n",
    "    scaler = None\n",
    "    if scale_data:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        seq = np.reshape(seq, (n, 1))\n",
    "        seq = scaler.fit_transform(seq).flatten()\n",
    "    return seq, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f529a7cf-462c-4cda-9974-3b9f86a395fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.546436Z",
     "iopub.status.busy": "2023-06-26T04:57:10.546268Z",
     "iopub.status.idle": "2023-06-26T04:57:10.550323Z",
     "shell.execute_reply": "2023-06-26T04:57:10.549618Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.546419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  5.  8. 13. 21. 34. 55. 89.]\n"
     ]
    }
   ],
   "source": [
    "fib_seq, _ = get_fib_seq(10, False)\n",
    "print(fib_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c730068-23d2-46d4-b28e-a03f685d398d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.551229Z",
     "iopub.status.busy": "2023-06-26T04:57:10.551094Z",
     "iopub.status.idle": "2023-06-26T04:57:10.556883Z",
     "shell.execute_reply": "2023-06-26T04:57:10.555988Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.551218Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fib_xy(total_fib_numbers, time_steps, train_frac, scale_data=True):\n",
    "    \"\"\"Returns train/test data constructed from the Fibonacci series.\n",
    "\n",
    "    Constructs training and test data (as X and y pairs),  where each row of X\n",
    "    consists of `time_steps` consecutive Fibonacci numbers and each y is the\n",
    "    Fibonacci number immediately following the last one in the corresponding X.\n",
    "\n",
    "    Args:\n",
    "        total_fib_numbers: Total number of terms of the Fibonacci series to use\n",
    "          to draw from to construct X/y pairs. (Excludes the initial 0, 1)\n",
    "        time_steps: Number of terms in each X sample.\n",
    "        train_frac: Fraction of data to designate as the training set.\n",
    "        scale_data: Whether to min-max-scale the data to the (0, 1) range.\n",
    "\n",
    "    Returns:\n",
    "        Shuffled training and testing pairs of (X, y) data and, optionally, a\n",
    "        MinMaxScaler object (or None). The returned X tensors are of dimensions\n",
    "        (num_samples, num_time_steps, num_features = 1).\n",
    "    \"\"\"\n",
    "    data, scaler = get_fib_seq(total_fib_numbers, scale_data)\n",
    "\n",
    "    y_indices = np.arange(time_steps, len(data), 1)\n",
    "    y = data[y_indices]\n",
    "    num_samples = len(y)\n",
    "    X = data[0:num_samples]\n",
    "    for i in range(1, time_steps):\n",
    "        X = np.column_stack((X, data[i : num_samples + i]))\n",
    "\n",
    "    # Now introduce random permutations\n",
    "    rand = np.random.RandomState(seed)\n",
    "    indices = rand.permutation(num_samples)\n",
    "    split = int(train_frac * num_samples)\n",
    "    train_indices = indices[0:split]\n",
    "    test_indices = indices[split:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    X_train = np.reshape(X_train, (len(X_train), time_steps, 1))\n",
    "    X_test = np.reshape(X_test, (len(X_test), time_steps, 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e16388e-58eb-40b8-ae29-ba121fff9a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.561138Z",
     "iopub.status.busy": "2023-06-26T04:57:10.560927Z",
     "iopub.status.idle": "2023-06-26T04:57:10.565330Z",
     "shell.execute_reply": "2023-06-26T04:57:10.564884Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.561116Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 8.],\n",
       "         [13.],\n",
       "         [21.]],\n",
       " \n",
       "        [[ 5.],\n",
       "         [ 8.],\n",
       "         [13.]],\n",
       " \n",
       "        [[ 2.],\n",
       "         [ 3.],\n",
       "         [ 5.]],\n",
       " \n",
       "        [[13.],\n",
       "         [21.],\n",
       "         [34.]],\n",
       " \n",
       "        [[21.],\n",
       "         [34.],\n",
       "         [55.]],\n",
       " \n",
       "        [[34.],\n",
       "         [55.],\n",
       "         [89.]]]),\n",
       " array([ 34.,  21.,   8.,  55.,  89., 144.]),\n",
       " array([[[ 55.],\n",
       "         [ 89.],\n",
       "         [144.]],\n",
       " \n",
       "        [[  1.],\n",
       "         [  2.],\n",
       "         [  3.]],\n",
       " \n",
       "        [[  3.],\n",
       "         [  5.],\n",
       "         [  8.]]]),\n",
       " array([233.,   5.,  13.]),\n",
       " None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fib_xy(12, 3, 0.7, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49338e-6f69-4108-b9f2-8768e475fa58",
   "metadata": {},
   "source": [
    "Great! Now let us build a model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bb36d08-ca58-4fad-b333-17350c8bf546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.566042Z",
     "iopub.status.busy": "2023-06-26T04:57:10.565932Z",
     "iopub.status.idle": "2023-06-26T04:57:10.571602Z",
     "shell.execute_reply": "2023-06-26T04:57:10.571218Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.566033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "time_steps = 20\n",
    "hidden_units = 2\n",
    "epochs = 30\n",
    "\n",
    "# Create a traditional RNN network\n",
    "def create_rnn(hidden_units, dense_units, input_shape, activations):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        SimpleRNN(\n",
    "            hidden_units, input_shape=input_shape, activation=activations[0]\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(dense_units, activation=activations[1]))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f45b17a9-8e29-49ce-90ea-0fd13455ad5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.572119Z",
     "iopub.status.busy": "2023-06-26T04:57:10.572030Z",
     "iopub.status.idle": "2023-06-26T04:57:10.647632Z",
     "shell.execute_reply": "2023-06-26T04:57:10.646205Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.572110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn = create_rnn(\n",
    "    hidden_units=hidden_units,\n",
    "    dense_units=1,\n",
    "    input_shape=(time_steps, 1),\n",
    "    activations=[\"tanh\", \"tanh\"],\n",
    ")\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edbf0d-0442-408c-bcdf-e507226ea2f2",
   "metadata": {},
   "source": [
    "Question\n",
    "> Why does the Simple RNN layer have 8 parameters?  \n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    (2 hidden units + 1 input feature) × (2 hidden units) + 2 biases\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "Now we are ready to create a larger dataset and train the model on it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff8d8f7e-cbe1-4fd0-917d-029b515f857d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.649055Z",
     "iopub.status.busy": "2023-06-26T04:57:10.648873Z",
     "iopub.status.idle": "2023-06-26T04:57:10.655111Z",
     "shell.execute_reply": "2023-06-26T04:57:10.654460Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.649042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "X_train, y_train, X_test, y_test, scaler = get_fib_xy(1200, time_steps, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a73ae6ed-5e2b-491e-9aeb-5e94bdec7c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:10.656644Z",
     "iopub.status.busy": "2023-06-26T04:57:10.656454Z",
     "iopub.status.idle": "2023-06-26T04:57:29.955856Z",
     "shell.execute_reply": "2023-06-26T04:57:29.955583Z",
     "shell.execute_reply.started": "2023-06-26T04:57:10.656632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 1s - loss: 0.0021 - 953ms/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 1s - loss: 0.0019 - 668ms/epoch - 809us/step\n",
      "Epoch 3/30\n",
      "826/826 - 1s - loss: 0.0018 - 638ms/epoch - 772us/step\n",
      "Epoch 4/30\n",
      "826/826 - 1s - loss: 0.0017 - 651ms/epoch - 789us/step\n",
      "Epoch 5/30\n",
      "826/826 - 1s - loss: 0.0016 - 643ms/epoch - 779us/step\n",
      "Epoch 6/30\n",
      "826/826 - 1s - loss: 0.0015 - 627ms/epoch - 759us/step\n",
      "Epoch 7/30\n",
      "826/826 - 1s - loss: 0.0015 - 621ms/epoch - 752us/step\n",
      "Epoch 8/30\n",
      "826/826 - 1s - loss: 0.0014 - 629ms/epoch - 761us/step\n",
      "Epoch 9/30\n",
      "826/826 - 1s - loss: 0.0013 - 635ms/epoch - 769us/step\n",
      "Epoch 10/30\n",
      "826/826 - 1s - loss: 0.0013 - 618ms/epoch - 748us/step\n",
      "Epoch 11/30\n",
      "826/826 - 1s - loss: 0.0012 - 631ms/epoch - 764us/step\n",
      "Epoch 12/30\n",
      "826/826 - 1s - loss: 0.0011 - 620ms/epoch - 750us/step\n",
      "Epoch 13/30\n",
      "826/826 - 1s - loss: 0.0010 - 651ms/epoch - 788us/step\n",
      "Epoch 14/30\n",
      "826/826 - 1s - loss: 9.0076e-04 - 634ms/epoch - 767us/step\n",
      "Epoch 15/30\n",
      "826/826 - 1s - loss: 7.9481e-04 - 635ms/epoch - 768us/step\n",
      "Epoch 16/30\n",
      "826/826 - 1s - loss: 6.6884e-04 - 612ms/epoch - 741us/step\n",
      "Epoch 17/30\n",
      "826/826 - 1s - loss: 5.4635e-04 - 615ms/epoch - 745us/step\n",
      "Epoch 18/30\n",
      "826/826 - 1s - loss: 4.4019e-04 - 624ms/epoch - 755us/step\n",
      "Epoch 19/30\n",
      "826/826 - 1s - loss: 3.4745e-04 - 618ms/epoch - 749us/step\n",
      "Epoch 20/30\n",
      "826/826 - 1s - loss: 2.6758e-04 - 623ms/epoch - 754us/step\n",
      "Epoch 21/30\n",
      "826/826 - 1s - loss: 2.0511e-04 - 617ms/epoch - 747us/step\n",
      "Epoch 22/30\n",
      "826/826 - 1s - loss: 1.6918e-04 - 618ms/epoch - 749us/step\n",
      "Epoch 23/30\n",
      "826/826 - 1s - loss: 1.4812e-04 - 616ms/epoch - 746us/step\n",
      "Epoch 24/30\n",
      "826/826 - 1s - loss: 1.3582e-04 - 644ms/epoch - 780us/step\n",
      "Epoch 25/30\n",
      "826/826 - 1s - loss: 1.1785e-04 - 619ms/epoch - 749us/step\n",
      "Epoch 26/30\n",
      "826/826 - 1s - loss: 1.1909e-04 - 622ms/epoch - 753us/step\n",
      "Epoch 27/30\n",
      "826/826 - 1s - loss: 1.1387e-04 - 644ms/epoch - 779us/step\n",
      "Epoch 28/30\n",
      "826/826 - 1s - loss: 1.0022e-04 - 643ms/epoch - 778us/step\n",
      "Epoch 29/30\n",
      "826/826 - 1s - loss: 9.2809e-05 - 628ms/epoch - 760us/step\n",
      "Epoch 30/30\n",
      "826/826 - 1s - loss: 9.7202e-05 - 637ms/epoch - 771us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f4a4dc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "578b886b-43e6-4464-927e-1d0a2f1a2d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:29.956599Z",
     "iopub.status.busy": "2023-06-26T04:57:29.956383Z",
     "iopub.status.idle": "2023-06-26T04:57:30.106189Z",
     "shell.execute_reply": "2023-06-26T04:57:30.105832Z",
     "shell.execute_reply.started": "2023-06-26T04:57:29.956589Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 698us/step - loss: 7.0155e-05\n",
      "12/12 [==============================] - 0s 628us/step - loss: 9.2670e-06\n",
      "Train set MSE =  7.015452138148248e-05\n",
      "Test set MSE =  9.266976121580228e-06\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_mse = model_rnn.evaluate(X_train, y_train)\n",
    "test_mse = model_rnn.evaluate(X_test, y_test)\n",
    "print(\"Train set MSE = \", train_mse)\n",
    "print(\"Test set MSE = \", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5bf6e-2161-4b34-bfa4-1c2f4ef7c1b3",
   "metadata": {},
   "source": [
    "## 9.3 Adding a Custom Attention Layer to the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0f5bf-fa90-4ab5-9a37-1b2aba2ecf0d",
   "metadata": {},
   "source": [
    "We will create the `Attention` class which inherits from Keras's `Layer` class. Our class will implement the Bahdanau attention mechanism.  \n",
    "In order to build a custom layer, Keras requires us to implement the `__init__()`, `build()` and `call()` methods. The `build` method \"lazily\" builds the weights and biases once the input shape is known. The `call()` method implements the forward pass of training. Everything else (computing gradients and tuning the weights via the backward pass) is taken care of by Keras.  \n",
    "\n",
    "See the Keras guide on [Making new layers and models via subclassing](https://keras.io/guides/making_new_layers_and_models_via_subclassing/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a657a0a0-c4a7-4941-a34c-ccde81281c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:30.106776Z",
     "iopub.status.busy": "2023-06-26T04:57:30.106689Z",
     "iopub.status.idle": "2023-06-26T04:57:30.112320Z",
     "shell.execute_reply": "2023-06-26T04:57:30.111903Z",
     "shell.execute_reply.started": "2023-06-26T04:57:30.106767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            name=\"attention_weight\",\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name=\"attention_bias\",\n",
    "            shape=(input_shape[1], 1),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Compute alignment scores and pass them thru the `tanh` function\n",
    "        e = K.tanh(K.dot(x, self.w) + self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        # Compute the attention weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to the format TensorFlow needs (adding back the removed dim)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62fb8b-0254-475c-afed-bd9c48d9f87c",
   "metadata": {},
   "source": [
    "We can now create an RNN with attention using the \"Functional API\" of Keras. Our attention layer expects a sequence as input, so we will have to make sure to return the entire sequence of hidden states from our SimpleRNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b240abdb-7f6b-418d-a948-60f9c566ad30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:30.113145Z",
     "iopub.status.busy": "2023-06-26T04:57:30.112894Z",
     "iopub.status.idle": "2023-06-26T04:57:30.116248Z",
     "shell.execute_reply": "2023-06-26T04:57:30.115872Z",
     "shell.execute_reply.started": "2023-06-26T04:57:30.113123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rnn_with_attention(\n",
    "    hidden_units, dense_units, input_shape, activation\n",
    "):\n",
    "    x = Input(shape=input_shape)\n",
    "    rnn_layer = SimpleRNN(\n",
    "        hidden_units, return_sequences=True, activation=activation\n",
    "    )(x)\n",
    "    attention_layer = Attention()(rnn_layer)\n",
    "    outputs = Dense(dense_units, trainable=True, activation=activation)(\n",
    "        attention_layer\n",
    "    )\n",
    "    model = Model(x, outputs)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50241826-4e2b-4552-a450-2bfc71b45f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:30.117071Z",
     "iopub.status.busy": "2023-06-26T04:57:30.116907Z",
     "iopub.status.idle": "2023-06-26T04:57:30.209157Z",
     "shell.execute_reply": "2023-06-26T04:57:30.208843Z",
     "shell.execute_reply.started": "2023-06-26T04:57:30.117060Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=TensorShape([None, 20, 2])\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20, 1)]           0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 20, 2)             8         \n",
      "                                                                 \n",
      " attention_1 (Attention)     (None, 2)                 22        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_attention = create_rnn_with_attention(\n",
    "    hidden_units=hidden_units,\n",
    "    dense_units=1,\n",
    "    input_shape=(time_steps, 1),\n",
    "    activation=\"tanh\",\n",
    ")\n",
    "model_attention.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fcc3d-fc9a-4bb2-8c70-78236fe1e347",
   "metadata": {},
   "source": [
    "Question\n",
    "> Why does the Attention layer have 22 parameters?  \n",
    "\n",
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "    20 \"weights\" for the 20 observations (`time_steps`) outputted via `return_sequences=True` + 2 \"biases\" for the 2 hidden units\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "We can now train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfb7b07c-3876-409f-8949-ed346837c985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:30.211956Z",
     "iopub.status.busy": "2023-06-26T04:57:30.211796Z",
     "iopub.status.idle": "2023-06-26T04:57:51.290847Z",
     "shell.execute_reply": "2023-06-26T04:57:51.290527Z",
     "shell.execute_reply.started": "2023-06-26T04:57:30.211944Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "826/826 - 1s - loss: 0.0018 - 1s/epoch - 1ms/step\n",
      "Epoch 2/30\n",
      "826/826 - 1s - loss: 0.0017 - 680ms/epoch - 823us/step\n",
      "Epoch 3/30\n",
      "826/826 - 1s - loss: 0.0016 - 685ms/epoch - 830us/step\n",
      "Epoch 4/30\n",
      "826/826 - 1s - loss: 0.0016 - 691ms/epoch - 837us/step\n",
      "Epoch 5/30\n",
      "826/826 - 1s - loss: 0.0016 - 677ms/epoch - 819us/step\n",
      "Epoch 6/30\n",
      "826/826 - 1s - loss: 0.0015 - 697ms/epoch - 844us/step\n",
      "Epoch 7/30\n",
      "826/826 - 1s - loss: 0.0015 - 678ms/epoch - 821us/step\n",
      "Epoch 8/30\n",
      "826/826 - 1s - loss: 0.0015 - 690ms/epoch - 835us/step\n",
      "Epoch 9/30\n",
      "826/826 - 1s - loss: 0.0015 - 674ms/epoch - 816us/step\n",
      "Epoch 10/30\n",
      "826/826 - 1s - loss: 0.0015 - 696ms/epoch - 843us/step\n",
      "Epoch 11/30\n",
      "826/826 - 1s - loss: 0.0015 - 723ms/epoch - 875us/step\n",
      "Epoch 12/30\n",
      "826/826 - 1s - loss: 0.0015 - 699ms/epoch - 847us/step\n",
      "Epoch 13/30\n",
      "826/826 - 1s - loss: 0.0014 - 675ms/epoch - 817us/step\n",
      "Epoch 14/30\n",
      "826/826 - 1s - loss: 0.0014 - 688ms/epoch - 832us/step\n",
      "Epoch 15/30\n",
      "826/826 - 1s - loss: 0.0014 - 695ms/epoch - 841us/step\n",
      "Epoch 16/30\n",
      "826/826 - 1s - loss: 0.0014 - 682ms/epoch - 825us/step\n",
      "Epoch 17/30\n",
      "826/826 - 1s - loss: 0.0014 - 690ms/epoch - 835us/step\n",
      "Epoch 18/30\n",
      "826/826 - 1s - loss: 0.0014 - 704ms/epoch - 852us/step\n",
      "Epoch 19/30\n",
      "826/826 - 1s - loss: 0.0014 - 687ms/epoch - 832us/step\n",
      "Epoch 20/30\n",
      "826/826 - 1s - loss: 0.0014 - 676ms/epoch - 819us/step\n",
      "Epoch 21/30\n",
      "826/826 - 1s - loss: 0.0014 - 684ms/epoch - 827us/step\n",
      "Epoch 22/30\n",
      "826/826 - 1s - loss: 0.0014 - 678ms/epoch - 821us/step\n",
      "Epoch 23/30\n",
      "826/826 - 1s - loss: 0.0014 - 680ms/epoch - 823us/step\n",
      "Epoch 24/30\n",
      "826/826 - 1s - loss: 0.0014 - 677ms/epoch - 820us/step\n",
      "Epoch 25/30\n",
      "826/826 - 1s - loss: 0.0014 - 676ms/epoch - 819us/step\n",
      "Epoch 26/30\n",
      "826/826 - 1s - loss: 0.0014 - 685ms/epoch - 830us/step\n",
      "Epoch 27/30\n",
      "826/826 - 1s - loss: 0.0014 - 683ms/epoch - 827us/step\n",
      "Epoch 28/30\n",
      "826/826 - 1s - loss: 0.0014 - 682ms/epoch - 826us/step\n",
      "Epoch 29/30\n",
      "826/826 - 1s - loss: 0.0014 - 686ms/epoch - 831us/step\n",
      "Epoch 30/30\n",
      "826/826 - 1s - loss: 0.0014 - 703ms/epoch - 851us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28eef66e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attention.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28039634-8498-4112-9478-c246966bb71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:51.291499Z",
     "iopub.status.busy": "2023-06-26T04:57:51.291335Z",
     "iopub.status.idle": "2023-06-26T04:57:51.457180Z",
     "shell.execute_reply": "2023-06-26T04:57:51.456861Z",
     "shell.execute_reply.started": "2023-06-26T04:57:51.291487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 740us/step - loss: 0.0014\n",
      "12/12 [==============================] - 0s 677us/step - loss: 0.0012\n",
      "Train set MSE =  0.0013820648891851306\n",
      "Test set MSE =  0.0012247657869011164\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_mse_attn = model_attention.evaluate(X_train, y_train)\n",
    "test_mse_attn = model_attention.evaluate(X_test, y_test)\n",
    "print(\"Train set MSE = \", train_mse_attn)\n",
    "print(\"Test set MSE = \", test_mse_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7af29d-023f-4a1c-ac1a-75e9bce9bc8b",
   "metadata": {},
   "source": [
    "This is a very contrived, simple example and the model with attention may or may not beat the one without.  \n",
    "We could potentially improve the model further by trying the following:\n",
    "- Hyperparameter tuning and model selection\n",
    "- Adding more layers to the network\n",
    "- Using `LSTM` units instead of `SimpleRNN`s\n",
    "- Building a network with convolution and pooling layers\n",
    "- Switching to the encoder-decoder model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707616ea-cf96-42e2-a69b-6ad75504843e",
   "metadata": {},
   "source": [
    "**Note:** We can use the `scaler` object to convert back to the original values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1dc34f-9035-4e34-91e6-73945b9460c3",
   "metadata": {},
   "source": [
    "**Personal Note:** Actually this dataset is pretty useless and not suited to this kind of model. I found out as much while trying to convert the predictions back to the original range as per the above note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06779d31-b189-49f9-a861-bd851545750a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:51.457857Z",
     "iopub.status.busy": "2023-06-26T04:57:51.457761Z",
     "iopub.status.idle": "2023-06-26T04:57:51.555931Z",
     "shell.execute_reply": "2023-06-26T04:57:51.555628Z",
     "shell.execute_reply.started": "2023-06-26T04:57:51.457848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example test case (unscaled):\n",
      "[1.43670136e+188 2.32463163e+188 3.76133300e+188 6.08596463e+188\n",
      " 9.84729763e+188 1.59332623e+189 2.57805599e+189 4.17138221e+189\n",
      " 6.74943820e+189 1.09208204e+190 1.76702586e+190 2.85910790e+190\n",
      " 4.62613377e+190 7.48524167e+190 1.21113754e+191 1.95966171e+191\n",
      " 3.17079925e+191 5.13046096e+191 8.30126022e+191 1.34317212e+192]\n",
      "\n",
      "\n",
      "The correct next term is: 8.301260217870547e+191 + 1.34317211819719e+192 = 2.1732981399842448e+192\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "The model predicted: 7.105794145798422e+247\n"
     ]
    }
   ],
   "source": [
    "fib_seq, _ = get_fib_seq(920, False)\n",
    "\n",
    "example = fib_seq[900:]\n",
    "print(f\"Example test case (unscaled):\\n{example}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "actual_next_term = example[-2] + example[-1]\n",
    "print(\n",
    "    f\"The correct next term is: {example[-2]} + {example[-1]} =\"\n",
    "    f\" {actual_next_term}\"\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "example_scaled = scaler.transform(np.reshape(example, (time_steps, 1)))\n",
    "predicted_term = model_attention.predict(np.expand_dims(example_scaled, 0))\n",
    "predicted_term_scaled = predicted_term[0][0]\n",
    "predicted_term_scaled\n",
    "print(f\"The model predicted: {scaler.inverse_transform([[predicted_term_scaled]])[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4146e-5f2a-4277-ae3c-4a7173d09e7a",
   "metadata": {},
   "source": [
    "My first reaction was: \"Why are they so far off?!\" Then I looked at a few arbitrary 20-term sub-sequences of the Fibonacci series and got the exact same result. And by \"exact same result\" I don't mean \"same huge error\". No! I mean the exact same prediction!! As a matter of fact, let's take a look at the model's predictions on the entire test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b022df-d838-4333-91d0-82802f270748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T04:57:51.556570Z",
     "iopub.status.busy": "2023-06-26T04:57:51.556396Z",
     "iopub.status.idle": "2023-06-26T04:57:51.598030Z",
     "shell.execute_reply": "2023-06-26T04:57:51.597693Z",
     "shell.execute_reply.started": "2023-06-26T04:57:51.556559Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 653us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161349],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00424584],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00260472],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00164442],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00872936],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161115],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161845],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161539],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043],\n",
       "       [0.00161043]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attention.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121298e6-13e0-4dcf-9a63-8f1768f466f8",
   "metadata": {},
   "source": [
    "Yup! They are mostly identical. Why? Because the $1200^{th}$ Fibonacci number has 250 digits (‼️) and when you map a range as wide as $(1, F_{1200})$ to the (0, 1) range in the scaling step, you can't expect a much better result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6f3d1-7bba-4ef0-9ff6-721353886287",
   "metadata": {},
   "source": [
    "If I get a chance later on, I will try to re-do this chapter with the sunspot dataset (from ch. 7) instead of this contrived Fibonacci-based one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
